{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities, Expected Values, and Effective Altruism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilities can be confusing, and the ways we talk about them in everyday life do not help with that confusion. If someone says you have a modest chance of something, what does that mean? This tweet caught my eye the other day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">1,700 people answered a survey that asked them to attach probabilities to 23 common words and phrases. The results are summarized in the figure. There’s a real possibility that it’s is the most interesting chart you’ll see this week. <a href=\"https://t.co/rwiwC4uqF2\">https://t.co/rwiwC4uqF2</a> <a href=\"https://t.co/CsuFGFBN72\">pic.twitter.com/CsuFGFBN72</a></p>&mdash; Arvind Narayanan (@random_walker) <a href=\"https://twitter.com/random_walker/status/1014487774064447488?ref_src=twsrc%5Etfw\">July 4, 2018</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">1,700 people answered a survey that asked them to attach probabilities to 23 common words and phrases. The results are summarized in the figure. There’s a real possibility that it’s is the most interesting chart you’ll see this week. <a href=\"https://t.co/rwiwC4uqF2\">https://t.co/rwiwC4uqF2</a> <a href=\"https://t.co/CsuFGFBN72\">pic.twitter.com/CsuFGFBN72</a></p>&mdash; Arvind Narayanan (@random_walker) <a href=\"https://twitter.com/random_walker/status/1014487774064447488?ref_src=twsrc%5Etfw\">July 4, 2018</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was interesting and nicely shows that \"with low probability\", \"rarely\", and even \"unlikely\" mean many differet things to many different people. As an example, Allen Downey suggests the next time someone says that they are 99% sure of something, offer to take a bet where they give you 99:1 odds. Obviosuly, they will likely take back their statement and say you are being far too literal. \n",
    "\n",
    "But qualitative interpretations of quantitative probabilites can lead to a lot of trouble. \n",
    "Allen Downey actually has a lot of [good thoughts](http://allendowney.blogspot.com/2016/11/why-are-we-so-surprised.html) on this and other misinterpretations of probability with regards to election results that are worth pondering in general. For example, everyone seemed surprised by a Trump win, who was given roughly a 30% chance by FiveThirtyEight. However, those same people would not have been shocked to see a coin come up heads twice in a row? Even if we take the Upshot's prediction of around 10% for Trump, should it really be that surprising?\n",
    "\n",
    "Well unfortunately it is to many. The problem is that many interpret 70%-30% like a prediction of American football scores or a poll where 70% of the voters decided on one side. Clearly, work needs to be done on helping the general public better understand this. \n",
    "\n",
    "Another interesting problem Downey points out is the difficulty in comparing probabilites. He gives the example of two models that predict a win probability of 70% and 99%. If one were instead to take two measurements 70 units and 99 units, the weight would likely be reported as the average +/- the standard error, which is approximately 84.5 +/- 14.5 units.\n",
    "\n",
    "However, this might indicate a chance that the true value could be greater than 100, which is clearly not true of probabilites. Furthermore, with probabilites, 84.5% is not really a good midpoint between 70% and 99%. Downey contends that we should be using **log-odds** to properly compare probabiliteis. The log-odds of a probability $p$ is $\\log{\\left(\\frac{p}{1-p}\\right)}$ and the graph is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1167308d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAF5CAYAAAAcQxneAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nabMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1168c21d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "p = np.linspace(0.0001,.9999,1000)\n",
    "plt.plot(p, np.log(p/(1-p)))\n",
    "plt.xlabel(r'$p$')\n",
    "plt.ylabel(r'$\\log{\\left(\\frac{p}{1-p}\\right)}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using log-odds, Downey calculates that the \"most meaningful midpoint\" between 70% and 99% is 94%.\n",
    "\n",
    "As for why one should use the log-odds to calculate differences in probability, Downey tweeted that \"the distance between two points in log-odds space is proportional to the information it would take to get you from one point to the other, in the sense of a Bayesian update.\" And if you think about small probabilites, the distance in log-odds space is a much better metric. For example, the difference between $p_1=\\frac{1}{1000}$ and $p_2=\\frac{1}{10000}$ is $p_1 - p_2 = \\frac{1}{1000} - \\frac{1}{10000} = \\frac{9}{10000}$. However, these probabilities are different by an order of magnitude and the distance in log-odds space is 1.0004, which is pretty close to the log-odds difference between 50% and 91%.\n",
    "\n",
    "### How do we know if we were right? ###\n",
    "\n",
    "Often times, researchers in effective altruism will roughly estimate the small probabilities for future catastrophic events. However, many of these are single-case events, so how do we even interpret these probabilities. For example, if I was a researcher on existential risk in 1999 and claimed there was a $\\frac{1}{1000}$ probability Y2K led to the end of the world, what does that even mean? Does that mean if we ran through the history of the world 1000 times, then the world would roughly end once out of those 1000 separate histories. How do we ever confirm or deny this? The human race will be wiped out or it won't, there is seemingly no information that can properly evaluate the probability estimate.\n",
    "\n",
    "In general, dealing with single-case events and probability can get can be tough. For example, were those who predicted that Clinton had a 90% chance to beat Trump just wrong or unlucky? How about when we say that a criminal has a 55% chance of reoffending, what are we really saying? The criminal will either offend or he won't, there are no inherent frequencies.\n",
    "\n",
    "The following tweet brought up an interesting discussion the other day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Thomas Jefferson and John Adams died OTD in 1826, exactly 50 years, to the day, after signing of the Declaration of Independence. <br><br>The probability of this happening is one, because it happened.</p>&mdash; karl rohe (@karlrohe) <a href=\"https://twitter.com/karlrohe/status/1014529810566139904?ref_src=twsrc%5Etfw\">July 4, 2018</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Thomas Jefferson and John Adams died OTD in 1826, exactly 50 years, to the day, after signing of the Declaration of Independence. <br><br>The probability of this happening is one, because it happened.</p>&mdash; karl rohe (@karlrohe) <a href=\"https://twitter.com/karlrohe/status/1014529810566139904?ref_src=twsrc%5Etfw\">July 4, 2018</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I guess this is technically true, but it fails to answer our most basic question: \"what were the chances?\" For this question, we need to think about \"reference classes.\" (Go into Allen Downey's [discussion](http://allendowney.blogspot.com/2015/11/recidivism-and-single-case-probabilities.html) of reference classes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*More Things to go into:* \n",
    "\n",
    "Should have thoughts here on Ord and Sandberg paper on methodological challenges, particularly how they use the law of total probability.\n",
    "\n",
    "Need for uncertainties can be further demonstrated by their work on Fermi Paradox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's play a game ###\n",
    "\n",
    "Here's the game. I am going to flip a coin, and I'll even flip a fair one for you. If the coin comes up heads, you win \\$2 profit for every \\$1 you bet (for a total of \\$3). However, if the coin comes up tails, you lose everything. You start with $1, so what do you do?\n",
    "\n",
    "Well the obvious answer is that you bet on heads. Let's look at the expected value of profit when betting $1 on heads.\n",
    "\n",
    "Expected Profit for \\$1 bet $ = 0.5*(2.0) + 0.5*(-1.0) = \\$ 0.5$\n",
    "\n",
    "That is an expected fifty cent (or 50%) profit per round; You should definitely play this game! Another way to say this is that since the coin lands on heads 50% of the time, I should be giving you even money, 1:1 odds, yet I am giving you 2:1 odds, so this is a clear betting oppurtunity. \n",
    "\n",
    "So you play the game and bet your whole dollar in the first round. The coin comes up tails. So much for averages! You have just experienced what is often called *Gambler's Ruin*...\n",
    "\n",
    "This raises the question, should you really have bet that whole $1?\n",
    "\n",
    "Let's do the same math as before for a bet of $x$ cents between \\$0.0 and \\$1.0.\n",
    "\n",
    "Expected Profit for bet of size $x = 0.5*(2*x) + 0.5*(-x) = 0.5*x $\n",
    "\n",
    "For the player, this is obviously maximized when $x$ is as large as possible. Therefore, the player would bet the whole $1 to maximize the expected projit and \"risk ruin.\"\n",
    "\n",
    "Some of you may be thinking that I am doing this wrong -- what I really should be optimizing is the expected amount of money in the bankroll after a bet, not just the expected profit. Well let's do it out and see:\n",
    "\n",
    "Expected Bankroll after bet of size $x = 0.5*(1+2*x) + 0.5*(1-x) = 1 + 0.5*x $\n",
    "\n",
    "This is again maximized when $x$ equals our whole bankroll and does not change our answer.\n",
    "\n",
    "If you played this game for 10 rounds, and bet your whole bankroll each round to maximize your expected return, there is a $\\left(\\frac{1}{2}\\right)^{10} = \\frac{1}{1024}$ chance that you have won \\$59,049 and a $\\frac{1023}{1024}=99.9%$ you end up bankrupt.\n",
    "\n",
    "This is obvioulsy not a very good way to make money on a game *where you have the potential to and should be making lots of it*!\n",
    "\n",
    "### The Kelly Criterion ###\n",
    "\n",
    "So what do you do? How do you bet the *optimal fraction* $f$ of your bankroll, in order to avoid ruin and still maximize profits for the long term. The answer is given by the **Kelly Critierion** and was actually originally derived from information theoretic principles.\n",
    "\n",
    "Let's focus on the long term bankroll for a bit. Assume you have an initial bankroll $B_0$ and each game you have a probability $p$ of winning the bet, which will yield $\\$b$ in profit.\n",
    "\n",
    "With this info, let's try to find the optimum value of $f$, the fraction you should bet each round. \n",
    "\n",
    "Let's look at our bankroll after the first round $B_1$. There are two distinct possibilites:\n",
    "\n",
    "You win, and your bankroll is increased by profit per dollar * dollars bet: $B_1 = B_0 + b*(fB_0) = (1+bf)B_0$\n",
    "\n",
    "You lose, and your bankroll is reduced by the amount you bet: $B_1 = B_0 - fB_0 = (1-f)B_0$\n",
    "\n",
    "Therefore, after each round, your bankroll is either multiplied by the factor $(1+bf)$ if you win or $(1-f)$ if you lost. It is not too hard to see then that after $n$ games with $w$ winning rounds, your bankroll will be as follows:\n",
    "\n",
    "$B_n = (1+bf)^w (1-f)^{n-w} B_0 $\n",
    "\n",
    "And the *Gain* after $n$ rounds is just equal to that multiplictive factor. I.e., $\\text{Gain}_n = (1+bf)^w (1-f)^{n-w}$\n",
    "\n",
    "The Kelly Criterion is then the $f$ that maximizes either the geometric mean of the gain of the arithmetic mean of the log of the gain. I refer you to these helpful [notes](https://pdfs.semanticscholar.org/presentation/3a8e/f144ca690f8c3530e9c1f587ab753e2922ce.pdf), which much of this is based on, for more intuition behind these statements.\n",
    "\n",
    "### My Preferred Derivation ###\n",
    "\n",
    "Our strategy is to bet a fixed fraction $f$ of our wealth on this favorable bet that we have found. Let us examine our average return in the long run. Note: the derivation here is not completely rigorous, but follows the approach given [here](http://www.elem.com/~btilly/kelly-criterion/).\n",
    "\n",
    "After each round of betting, our initial net worth $B_0$ is multiplied by a random variable $X$. So after $n$ rounds of the betting, our net worth $B_n$ is just our initial wealth multiplied by the random outcomes of our $n$ bets:\n",
    "\n",
    "$B_n = X_n \\cdots X_2 X_1 B_0 $\n",
    "\n",
    "Statistics is much easier with random variables that are added together rather than multiplied together. Therefore, let's do a log transformation.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "B_n &= B_0 \\left( e^{\\log{(X_1 X_2 \\cdots X_n)}} \\right) \\\\\n",
    "&= B_0 \\left( e^{\\log{X_1} + \\log{X_2} + \\cdots + \\log{X_n}} \\right) \n",
    "\\end{align*}\n",
    "$$\n",
    "   \n",
    "\n",
    "Let us then take the expected value of each side and recognize that $E(\\log{X_1} + log{X_2} + \\cdots + log{X_n}) = n*E(\\log{X})$ Thus, our average final wealth after $n$ bets is:\n",
    "\n",
    "$E(B_n) = B_0 \\left( e^{E(\\log{X})} \\right)^n $\n",
    "\n",
    "Thus, it can be seen that the initial net worth is multiplied on average by a factor of $\\left( e^{E(\\log{X})} \\right)$ after each round of betting.\n",
    "\n",
    "In our example, the longterm rate of return is $e^{E(\\log{X})} = e^{p\\log(X_{win}) + (1-p)\\log{(X_{loss})}} $\n",
    "\n",
    "We see that for our original example, if we simply bet our whole bankroll each round. \n",
    "\n",
    "$E(B_n) = e^{({(0.5)\\log{2} + (0.5)\\log{0}})} = e^{-\\infty} = 0$\n",
    "\n",
    "Let's instead take the derivative to try to find the optimum value.\n",
    "\n",
    "It is easy to see that to maximize \n",
    "\n",
    "$ e^{E(\\log{X})} $ we must maximixe $ E(\\log{X}) $ where $X_{win} = (1 + bf)$ an $X_{loss} = (1-f)$, which are exactly the factors we saw before with the previous approach. \n",
    "\n",
    "Thus, \n",
    "\n",
    "$ E(\\log{X}) = p\\log{(1+bf)} + (1-p)\\log{(1-f)}$ \n",
    "\n",
    "and,\n",
    "\n",
    "$ \\frac{d E(\\log{X})}{d f} = p\\frac{b}{1+bf} + (1-p)\\frac{-1}{1-f} \\overset{\\mathrm{set}}{=} 0$\n",
    "\n",
    "By doing solving for the optimal $f$, we then get to the expression:\n",
    "\n",
    "$ f = \\frac{pb - (1-p)}{b}$ \n",
    "\n",
    "Often, people will call the expression in the numberator $pb - (1-p)$ the *edge*, while $b$ is commonly reffered to as the *odds*. Thus, we get the interpretation of the Kelly Criterion as *edge over odds*. \n",
    "\n",
    "#### Back to our original example ####\n",
    "\n",
    "To find the optimal wager for our original game, we then simply plug our values into the above expression.\n",
    "\n",
    "$ f = \\frac{(0.5)(2) - (1-0.5)}{2} = \\frac{0.5}{2} = 0.25 $.\n",
    "\n",
    "Thus, we see that the optimal bet is to bet 25% of our bankroll each round. And we can see that our long term rate of return for each round will be.\n",
    "\n",
    "$e^{E(log{X})} = e^{p\\log(1+bf) + (1-p)\\log{(1-f)}} = e^{(0.5)\\log(1+(2)(0.25)) + (1-0.5)\\log{(1-0.25)}} = 1.0607$ (a positive 6.07% return) \n",
    "\n",
    "Thus, after ten rounds our initial bankroll $B_0= \\$1$ will grow to $E(B_n) = (1.0607)^{10} B_0 = 1.802 $. This is actually lower than the mean promised by the method of betting one's whole bankroll each round. However, the distribution of returns is much less skewed. By using this optimal $f$ from the Kelly Criterion, we are promised a few things:\n",
    "\n",
    "* The Kelly Criterion maximizes the final wealth better than any other strategy\n",
    "\n",
    "* The Kelly Crierion maximizes the median of the final wealth better than any other strategy\n",
    "\n",
    "* The Kelly Criterion minimizes the amount of time  to reach a given final wealth\n",
    "\n",
    "This is not to say the Kelly Criterion is flawless. Betting using the Kelly Criterion can still lead to volatile returns and can be dangerous if certain parameters of the equation are estimated incorrectly. For example, many people will use a *fractional Kelly* strategy, in which they only bet a certain fraction of the Kelly $f$ because they fear they may be overestimating their win probability. There are other useful extensions of Kelly such as when betting on *multiple outcomes*. This is particularly useful when attempting to allocate bets in the stock market, for example.\n",
    "\n",
    "It's also worth looking back at what we have done to get here. We have essentially maximised the expected value of the *logarithm* of the wealth. This can be viewed as the *utility function* used in our example. Therefore, Kelly will maximize the expected utility of someone who has a logarithmic utility function. However, if the utility function is different, it will not. \n",
    "\n",
    "### Another Game: The St. Petersburg Lottery ###\n",
    "\n",
    "On [overcomingbias](www.overcomingbias.com), Robin Hanson [wrote](http://www.overcomingbias.com/2011/07/ignoring-small-chances.html) about a very famous paradox known as the [St. Petersburg Paradox/Lottery](https://en.wikipedia.org/wiki/St._Petersburg_paradox). The paradox has received much attention over on [lesswrong](https://www.lesswrong.com/) because the problem gets right to the crux of many of the issues lesswrong members think about. \n",
    "\n",
    "The problem is as follows:\n",
    "\n",
    "A fair coin is tossed and the game ends immedietely when the coin lands on tails. If tails appears on the first toss, the player wins \\$2. If the first toss is instead heads, the game continues. If tails appears on the second toss, the payout is doubled and the player wins \\$4. The game continues as such for as long as heads are tossed and the payout is doubled after each round. Since the probability of the game continuing also halves after each round, we run into some interesting behavior.\n",
    "\n",
    "For example, let's calculate the expected winnings from playing such a game:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "E &= \\frac{1}{2}*2 + \\frac{1}{4}*4 + \\frac{1}{8}*8 + \\cdots \\\\\n",
    "&= 1+1+1 + \\cdots \\\\\n",
    "&= \\infty \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The questiion then, is how much would/should one pay to play such a game. \n",
    "\n",
    "By using a pure expected value apprach, it seems that one should enter the game at any price -- even if it requires borrowing huge amounts of money to enter. Yet, many studies have been done to show that most people will definitely not do that. In his aforementioned blog post, Robin Hanson quotes the following paragraph from this interesting [paper](http://d.repec.org/n?u=RePEc:crf:wpaper:10-14&r=exp):\n",
    "\n",
    "```\n",
    "Nicholas Bernoulli … suggested that more than five tosses of heads are [seen as] morally impossible [and so ignored]. This proposition is experimentally tested through the elicitation of subjects‘ willingness-to-pay for various truncated versions of the Petersburg gamble that differ in the maximum payoff. … All gambles that involved probability levels smaller than 1/16 and maximum payoffs greater than 16 Euro elicited the same distribution of valuations. … The payoffs were as described …. but in Euros rather than in ducats. … The more senior students seemed to have a higher willingness-to-pay. … Offers increase significantly with income.\n",
    "```\n",
    "\n",
    "Clearly, people don't do great with small probabilites. For some context, let's look back at what some other famous mathematicions thought about small probabilites...\n",
    "\n",
    "According to Richard Epstein in his book *The Theory of Gambling and Statistical Logic*, d'Alembert \"promulgated the doctrine that a very small probability is practically equivalent to zero. However, he also believed that tossing three coins was different than three tosses of one coin, so perhaps he is not the greatest source on probabilitiy.\n",
    "\n",
    "Buffon apparently established that 1/10,000 was the lowest practical probability while the logician Charles Sanders Peirce believed that everything that can happen will happen. One lesson is that the strageness of small probabilities led a lot of smart people to belive some very weird things.\n",
    "\n",
    "As Robin Hanson also writes of the previously mentioned paper's results:\n",
    "\n",
    "```\n",
    "This isn’t plausibly explained by risk aversion, nor by a general neglect of possibilities with a <5% chance. I suspect this is more about analysis complexity, i.e., about limiting the number of possibilities we’ll consider at any one time. I also suspect this bodes ill for existential risk mitigation.\n",
    "```\n",
    "\n",
    "Now it's worth examining Daniel Bernoulli's eventual solution to the problem (yes, he provided the solution to his cousin's Nicholas Bernoulli's problem). Daniel proposed that one should not focus on the expected value, but rather the *expected utility*. By introducing a *utility function* with diminishing marginal utility of money, the expected utility can be finite while the expected value is still infinite. \n",
    "\n",
    "Bernoulli justified his reasoning and assumption of diminishing marginal utility as follows:\n",
    "\n",
    "```\n",
    "The determination of the value of an item must not be based on the price, but rather on the utility it yields…. There is no doubt that a gain of one thousand ducats is more significant to the pauper than to a rich man though both gain the same amount.\n",
    "```\n",
    "\n",
    "In particular, Daniel Bernoulli suggested the log-utility function $U(w)=\\log{(w)}$, which is obviously a function of wealth and has diminishing marginal utility built into it, due to the concavity of the logarithmic function.\n",
    "\n",
    "Using this model, Bernoulli was able to demonstrate how much a person of a given wealth should gamble on the theoretical St. Petersburg Lottery. For example, he came up with the following figures (numbers taken right from the [Wikipedia page](https://en.wikipedia.org/wiki/St._Petersburg_paradox)):\n",
    "\n",
    "* Wealth = \\$1,000,000: Should pay up to \\$20.28 to play\n",
    "* Wealth = \\$1,000: Should pay up to \\$10.95 to play\n",
    "* Wealth = \\$2: Should pay up to \\$3.35 (by borrowing money) to play\n",
    "\n",
    "### An Interesting Connection ###\n",
    "\n",
    "The astute reader may notice that much of this analysis, including the log-utility function, looks quite similar to that which we performed when deriving the Kelly Criterion. This is no coincidece, Daniel Bernoulli's results exactly equal those one would get by using the Kelly Criterion (he approached it by maximizing the geometric mean of the outcomes).\n",
    "\n",
    "Other readers may wonder what exactly makes the logarithmic function special. Well, for one, it makes for easier analysis. However, Owen Cotton-Barratt of the Future of Humanity institue at Oxford has provided [some theory](http://globalprioritiesproject.org/2015/02/part-5-theory-behind-logarithmic-returns/) behind mechanisms that might bring about logarithmic returns on investment. Cotton-Barratt also provides [some empirical evidence](http://globalprioritiesproject.org/2015/02/the-law-of-logarithmic-returns/) for the logarithmic form. If you are interested more in this topic, I highly suggest the [entire series of posts](http://globalprioritiesproject.org/2015/02/project-overview-problems-of-unknown-difficulty/) put together by Cotton-Barratt on the cost-effectiveness of problems of unknown difficulty. \n",
    "\n",
    "One other thing to note about log-utility is that it has [*risk-aversion*](https://en.wikipedia.org/wiki/Expected_utility_hypothesis#Risk_aversion) built directly into the functional form. Since $\\frac{d U}{d w} = \\frac{1}{w} > 0$ and $\\frac{d^2 U}{d w^2} = \\frac{-1}{w^2} < 0$, the function's curvature implies risk aversion (more to lose than to gain from taking a big risk). This also implies that if there are bets of equal expected value, one would always take the the bet with a lower variance of return. \n",
    "\n",
    "In contrast, a linear utility function would imply risk-neutrality, while a convex utility function would imply risk loving tendencies. Interestingly, there are those who argue that diminishing returns does not apply as a concept to charities (see [this post](https://concepts.effectivealtruism.org/concepts/diminishing-returns/)). For example, Michael Dickens [argues](http://effective-altruism.com/ea/wr/how_should_a_large_donor_prioritize_cause_areas/#fundamental-risk-aversion) that diminishing returns don't apply for work on existential risks, and he has praised Open Phil's philosophy of [risk agnostic giving](https://www.openphilanthropy.org/blog/hits-based-giving). (NOTE TO SELF: I actually don't fully understand his argument and should work to further understand his reasoning.)\n",
    "\n",
    "Additionally, Brian Tomasik has [written](The Case for Risky Investments) that charitible utility functions are approximately linear and risk-aversion shouldn't apply. However, he seemed to walk back that view calling it \"overly simplistic\" and has written a newer article entitled [\"When Should Altruists Be Financially Risk-Averse?\"](http://reducing-suffering.org/when-should-altruists-be-financially-risk-averse/) Interestingly, Tomasik and Dickens have both [encouraged](http://reducing-suffering.org/why-maximize-expected-value/) giving based solely in terms of expected value. \n",
    "\n",
    "Tomasik's arguments, in particular, are quite interesting -- even appealing to certain interpretations of quantum mechanics. However, one of his simpler and more compelling arguments for expected value giving is one of \"rule utilitarianism.\" Essentially, he is saying that if everyone makes decisions based on expected value this will imply the best possible consequences by the law of large numbers. Furthermore, \"we should praise people based on doing what seemed at the time to be the action of highest expected value, even if the person got unlucky with the actual outcome.\" However, I am not sure this is totally correct. To adapt an example from Holden Karnofsky's [2011 post on expected value estimates](https://blog.givewell.org/2011/08/18/why-we-cant-take-expected-value-estimates-literally-even-when-theyre-unbiased/), if a man is standing by a lake in his \\$5,000 custom suit and sees a kid drowning, should he simply let the kid drown because he realizes he could sell the suit and donate \\5,000 to save an estimated 1.5 lives? Should he be praised for this expected value decision? Perhaps he should be scolded for even spending so much on a suit and not using that money for chartiy? But maybe he needed the suit to fit in and get a job with a large income that has allowed him to donate more to charity than he ever would have been able to otherwise? I don't know, but it doesn't seem so clear to me. \n",
    "\n",
    "Let's not lose sight of the forest here. We have shown examples of situations where betting using an expected-value approach is clearly not ideal. For those of you familiar with [lesswrong](https://www.lesswrong.com/) discussions, the St. Petersburg Paradox may even remind you of [Pascal's Mugging](https://nickbostrom.com/papers/pascal.pdf) (this illustrative explanation by Nick Bostrom is even quite funny). However, there is debate regarding risk-aversion and charitible giving, as well as what a utility function should even look like for giving. And we also, know from earlier discussions that dealing with small probabilites is extremely tough. However, to many, the idea that one should use a pure expected value approach and should not consider risk-aversion when giving to existential risks is tough to swallow. I am one of those people.\n",
    "\n",
    "### My Current Concerns About an Expected Value Approach ###\n",
    "\n",
    "I admit that I may totally be wrong, and I am happy to be convinced otherwise. My effective altruist friend who convinced me to become vegetarian after living on a farm my whole life can back that up. So let me put forward some of my current concerns and perhaps you can see what evidence it will take to change my mind.\n",
    "\n",
    "** Pascal's Mugging and Gambler's Ruin **\n",
    "\n",
    "There's one thing I never understood about ...\n",
    "\n",
    "Buckley Program at Yale ... ///\n",
    "\n",
    "Expand upon Terrence Tao comment on quomodumque ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
