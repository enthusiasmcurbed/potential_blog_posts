{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities, Expected Values, and Effective Altruism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's play a game ###\n",
    "\n",
    "Here's the game. I am going to flip a coin, and I'll even flip a fair one for you. If the coin comes up heads, you win \\$2 profit for every \\$1 you bet (for a total of \\$3). However, it the coin comes up tails, you lose everything. You start with $1, so what do you do?\n",
    "\n",
    "Well the obvious answer is that you bet on heads. Let's look at the expected value of profit when betting $1 on heads.\n",
    "\n",
    "Expected Profit for \\$1 bet $ = 0.5*(\\$2.0) + 0.5*(\\$-1.0) = \\$ 0.5$\n",
    "\n",
    "That is am expected fifty cent (or 50%) profit per round; You should definitely play this game! Another way to say this is that since the coin lands on heads 50% of the time, I should be giving you even money, 1:1 odds, yet I am giving you 2:1 odds, so this is a clear betting oppurtunity. \n",
    "\n",
    "So you play the game and bet your whole dollar in the first round. The coin comes up tails. So much for averages! You have just experienced what is often called *Gambler's Ruin*...\n",
    "\n",
    "This raises the question, should you really have bet that whole $1?\n",
    "\n",
    "Let's do the same math as before for a bet of $x$ cents between \\$0.0 and \\$1.0.\n",
    "\n",
    "Expected Profit for bet of size $x = 0.5*(2*x) + 0.5*(-x) = 0.5*x $\n",
    "\n",
    "For the player, this is obviously maximized when $x$ is as large as possible. Therefore, the player would bet the whole $1 to maximize the expected projit and \"risk ruin.\"\n",
    "\n",
    "Some of you may be thinking that I am doing this wrong -- what I really should be optimizing is the expected amount of money in the bankroll after a bet, not just the expected profit. Well let's do it out and see:\n",
    "\n",
    "Expected Bankroll after bet of size $x = 0.5*(1+2*x) + 0.5*(1-x) = 1 + 0.5*x $\n",
    "\n",
    "This is again maximized when $x$ equals our whole bankroll and does not change our answer.\n",
    "\n",
    "If you played this game for 10 rounds, and bet your whole bankroll each round to maximize your expected return, there is a $\\left(\\frac{1}{2}\\right)^{10} = \\frac{1}{1024}$ chance that you have won \\$59,049 and a $\\frac{1023}{1024}=99.9%$ you end up bankrupt.\n",
    "\n",
    "This is obvioulsy not a very good way to make money on a game *where you have the potential to and should be making lots of it*!\n",
    "\n",
    "So what do you do? How do you bet the *optimal fraction* $f$ of your bankroll, in order to avoid ruin and still maximize profits for the long term. The answer is given by the **Kelly Critierion** and was actually originally derived from information theoretic principles.\n",
    "\n",
    "Let's focus on the long term bankroll for a bit. Assume you have an initial bankroll $B_0$ and each game you have a probability $p$ of winning the bet, which will yield $\\$b$ in profit.\n",
    "\n",
    "With this info, let's try to find the optimum value of $f$, the fraction you should bet each round. \n",
    "\n",
    "Let's look at our bankroll after the first round $B_1$. There are two distinct possibilites:\n",
    "\n",
    "You win, and your bankroll is increased by profit per dollar * dollars bet: $B_1 = B_0 + b*(fB_0) = (1+bf)B_0$\n",
    "\n",
    "You lose, and your bankroll is reduced by the amount you bet: $B_1 = B_0 - fB_0 = (1-f)B_0$\n",
    "\n",
    "Therefore, after each round, your bankroll is either multiplied by the factor $(1+bf)$ if you win or $(1-f)$ if you lost. It is not too hard to see then that after $n$ games with $w$ winning rounds, your bankroll will be as follows:\n",
    "\n",
    "$B_n = (1+bf)^w (1-f)^{n-w} B_0 $\n",
    "\n",
    "And the *Gain* after $n$ rounds is just equal to that multiplictive factor. I.e., $\\text{Gain}_n = (1+bf)^w (1-f)^{n-w}$\n",
    "\n",
    "The Kelly Criterion is then the $f$ that maximizes either the geometric mean of the gain of the arithmetic mean of the log of the gain. I refer you AGAIN these helpful [notes](https://pdfs.semanticscholar.org/presentation/3a8e/f144ca690f8c3530e9c1f587ab753e2922ce.pdf) for more intuition behind these statements.\n",
    "\n",
    "### My Preferred Derivation ###\n",
    "\n",
    "Our strategy is to bet a fixed fraction $f$ of our wealth on this favorable bet that we have found. Let us examine our average return in the long run.\n",
    "\n",
    "After each round of betting, our initial net worth $B_0$ is multiplied by a random variable $X$. So after $n$ rounds of the betting, our net worth $B_n$ is just our initial wealth multiplied by the random outcomes of our $n$ bets:\n",
    "\n",
    "$B_n = X_n \\cdots X_2 X_1 B_0 $\n",
    "\n",
    "Statistics is much easier with random variables that are added together rather than multiplied together. Therefore, let's do a log transformation.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "B_n &= B_0 \\left( e^{\\log{(X_1 X_2 \\cdots X_n)}} \\right) \\\\\n",
    "&= B_0 \\left( e^{\\log{X_1} + log{X_2} + \\cdots + log{X_n}} \\right) \n",
    "\\end{align*}\n",
    "$$\n",
    "   \n",
    "\n",
    "Let us then take the expected value of each side and recognize that $E(\\log{X_1} + log{X_2} + \\cdots + log{X_n}) = n*E(log{X})$ Thus, our average final wealth after $n$ bets is:\n",
    "\n",
    "$E(B_n) = B_0 \\left( e^{E(\\log{X})} \\right)^n $\n",
    "\n",
    "Thus, it can be seen that the initial net worth is multiplied on average by a factor of $\\left( e^{E(\\log{X})} \\right)$ after each round of betting.\n",
    "\n",
    "In our example, the longterm rate of return is $e^{E(log{X})} = e^{p\\log(X_{win}) + (1-p)\\log{(W_{loss})}} $\n",
    "\n",
    "We see that for our original example, if we simply bet our whole bankroll each round. \n",
    "\n",
    "$E(B_n) = e^{({(0.5)\\log{2} + (0.5)\\log{0}})} = e^{-\\infty} = 0$\n",
    "\n",
    "Let's instead take the derivative to try to find the optimum value.\n",
    "\n",
    "It is easy to see that to maximize \n",
    "\n",
    "$ e^{E(\\log{X})} $ we must maximixe $ E(\\log{X}) $ where $X_{win} = (1 + bf)$ an $X_{loss} = (1-f)$, which are exactly the factors we saw before with the previous approach. \n",
    "\n",
    "Thus, \n",
    "\n",
    "$ E(\\log{X}) = p\\log{(1+bf)} + (1-p)\\log{(1-f)}$ \n",
    "\n",
    "and,\n",
    "\n",
    "$ \\frac{d E(\\log{X})}{d f} = p\\frac{b}{1+bf} + (1-p)\\frac{-1}{1-f} \\overset{\\mathrm{set}}{=} 0$\n",
    "\n",
    "By doing solving for the optimal $f$, we then get to the expression:\n",
    "\n",
    "$ f = \\frac{pb - (1-p)}{b}$ \n",
    "\n",
    "Often, people will call the expression in the numberator $pb - (1-p)$ the *edge*, while $b$ is commonly reffered to as the *odds*. Thus, we get the interpretation of the Kelly Criterion as *edge over odds*. \n",
    "\n",
    "#### Back to our original example ####\n",
    "\n",
    "To find the optimal wager for our original game, we then simply plug our values into the above expression.\n",
    "\n",
    "$ f = \\frac{(0.5)(2) - (1-0.5)}{2} = \\frac{0.5}{2} = 0.25 $.\n",
    "\n",
    "Thus, we see that the optimal bet is to bet 25% of our bankroll each round. And we can see that our long term rate of return for each round will be.\n",
    "\n",
    "$e^{E(log{X})} = e^{p\\log(1+bf) + (1-p)\\log{(1-f)}} = e^{(0.5)\\log(1+(2)(0.25)) + (1-0.5)\\log{(1-0.25)}} = 1.0607$ (a positive 6.07% return) \n",
    "\n",
    "Thus, after ten rounds our initial bankroll $B_0= \\$1$ will grow to $E(B_n) = (1.0607)^{10} B_0 = 1.802 $. This is actually lower than the mean promised by the method of betting one's whole bankroll each round. However, the distribution of returns is much less skewed. By using this optimal $f$ from the Kelly Criterion, we are promised a few things:\n",
    "\n",
    "* The Kelly Criterion maximizes the final wealth better than any other strategy\n",
    "\n",
    "* Maximizes the median of the final wealth better than any other strategy\n",
    "\n",
    "* The Kelly Criteion minimizes the amount of time  to reach a given final wealth\n",
    "\n",
    "This is not to say the Kelly Criterion is flawless. Betting using the Kelly Criterion can still lead to volatile returns and can be dangerous if certain parameters of the equation are estimated incorrectly. For example, many people will use a *fractional Kelly* strategy, in which they only bet a certain fraction of the Kelly $F$ because they fear they may be overestimating their win probability. There are other useful extensions of Kelly such as when betting on *multiple outcomes*. This is particularly useful when attempting to allocate bets on the stock market, for example.\n",
    "\n",
    "It's also worth looking back at what we have done to get here. We have essentially maximised the expected value of the *logarithm* of the wealth. This can be viewed as the *utility function* used in our example. Therefore, Kelly will maximize the expected utility of someone who has a logarithmic utility function. However, if the utility function is different, it will not. \n",
    "\n",
    "### Another Game: The St. Petersburg Lottery ###\n",
    "\n",
    "On www.overcomingbias.com, Robin Hanson [wrote](http://www.overcomingbias.com/2011/07/ignoring-small-chances.html) about a very famous paradox known as the [St. Petersburg Paradox/Lottery](https://en.wikipedia.org/wiki/St._Petersburg_paradox). The paradox has received much attention over on [lesswrong](https://www.lesswrong.com/) because the problem gets right to the crux of many of the issues lesswrong members think about. \n",
    "\n",
    "The problem is as follows:\n",
    "\n",
    "A fair coin is tossed and the game ends immedietely when the coin lands on tails. If tails appears on the first toss, the player wins \\$2. If the first toss is instead heads, the game continues. If tails appears on the second toss, the payout is doubled and the player wins \\$4. The game continues as such for as long as heads are tossed and the payout is doubled after each round. Since the probability of the game continuing also half each round, we run into some interesting behavior.\n",
    "\n",
    "For example, let's calculate the expected value of playing such a game:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "E &= \\frac{1}{2}*2 + \\frac{1}{4}*4 + \\frac{1}{8}*8 + \\cdots \\\\\n",
    "&= 1+1+1 + \\cdots \\\\\n",
    "&= \\infty \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
